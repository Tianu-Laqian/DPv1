# DPv1

存档自己在工作中做数据采集和清理中高频率使用的的py脚本，用法多数为在命令行 `python "所使用的py脚本"`。存档一些爬虫。面向数据清理的脏活累活的自动化清理脚本汇总，虽简单，但好用。

如使用，更多探索前往对应的py脚本自己diy。

**常规食用手法：**

一、你用xpath提取了上千行数据，希望快速对它进行一些预处理。

二、对csv，excel希望做一些快速的处理。

三、眼馋网页中的表格和数据，希望简单地拉取下来进一步处理。

## need_txt（读取input.txt，按行清理数据）

### 0_去除多余标点符号并添加前缀.py

把你提取的数行数据放入txt文件中。打开py，在preserved_chars 中去定义需要保留的标点，使用  `-s  “xxxx” `为每一行添加你所需要的前缀。

### 1_去除括号内的所有.py

如名。

### 2_初步处理，行数x2.py

删除行首的中文数字标号，例如"（一）"、”一、“，过滤不需要的标点符号，拆分主名称和括号内容，分别写入两次。

### 3_自动匹配后缀.py

结合脚本2，自动填充后缀职称。

### 4_批量打开所有url.py

为你批量打开所有url，鸡肋功能 : D。

### 5_行x2.py

非常纯粹的为你每一行x2

## 胡润榜单数据爬虫

抓取、清理、格式化。大致保证了该文件夹下所有输出csv的字段名一致，对各个胡润榜单的数据进行匹配，可以最终合并，进行数据探索。部分需要下载对应的json数据在本地进行处理。

思路：对同行的多个人名进行展开，阐述人物关系，从json中读取数据，有啥就呈现啥。

输出示例可见`输出示例_2024年胡润百富榜.csv`

## simple_spider

爬虫和数据清理实验，自存档。

## 0_快速提取网页中所有的表格.py

使用`python 0_快速提取网页中所有的表格.py`快速与我进行交互吧~近期最常用的py，强推了：D

## 00_快速填充excel中所有数据.py

为你快速填充excel中的空单元格数据











